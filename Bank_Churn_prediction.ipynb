{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Churn Prediction Proyect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este proyecto vamos a analizar algunos datos del banco \"Beta Bank\" ya que los clientes se estan saliendo del banco poco a poco, asi que nuestro trabajo sera predecir si alguno de \n",
    "los clientes actuales dejara el banco pronto para asi poder tomar medidas y evitar que esto suceda. Crearemos un modelo con el maximo F1 posible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desarrollar un modelo predictivo eficiente que identifique con alta precisión a los clientes con mayor riesgo de abandonar los servicios de Beta Bank. Este modelo ayudará a la entidad bancaria a implementar estrategias proactivas para la retención de clientes, optimizando recursos y mejorando la satisfacción del cliente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importacion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulación y análisis de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "# Modelos de machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis y preparacion de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploracion Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Características\n",
    "- RowNumber: índice de cadena de datos\n",
    "- CustomerId: identificador de cliente único\n",
    "- Surname: apellido\n",
    "- CreditScore: valor de crédito\n",
    "- Geography: país de residencia\n",
    "- Gender: sexo\n",
    "- Age: edad\n",
    "- Tenure: período durante el cual ha madurado el depósito a plazo fijo de un cliente (años)\n",
    "- Balance: saldo de la cuenta\n",
    "- NumOfProducts: número de productos bancarios utilizados por el cliente\n",
    "- HasCrCard: el cliente tiene una tarjeta de crédito (1 - sí; 0 - no)\n",
    "- IsActiveMember: actividad del cliente (1 - sí; 0 - no)\n",
    "- EstimatedSalary: salario estimado\n",
    "\n",
    "Objetivo\n",
    "- Exited: El cliente se ha ido (1 - sí; 0 - no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver tenemos algunos datos nulos en Tenure, exactamente 909 los cuales representan un 9% de los datos, no es un porcentaje muy alto, pero si lo suficiente como para tener que tomar una decision sobre ellos ya que no podemos dejarlos asi, ya que podrian afectar a nuestro modelo. \n",
    "\n",
    "Tenemos varias opciones las cuales son las siguientes:\n",
    "\n",
    "- Eliminarlos\n",
    "- Rellenarlos con la media, mediana o moda\n",
    "- Rellenarlos con un valor aleatorio\n",
    "\n",
    "Decidimos eliminarlos ya que no es un porcentaje muy alto y no afectara mucho a nuestro modelo, y asi no tendremos que preocuparnos de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminacion de datos nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Tenure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9091 entries, 0 to 9998\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        9091 non-null   int64  \n",
      " 1   CustomerId       9091 non-null   int64  \n",
      " 2   Surname          9091 non-null   object \n",
      " 3   CreditScore      9091 non-null   int64  \n",
      " 4   Geography        9091 non-null   object \n",
      " 5   Gender           9091 non-null   object \n",
      " 6   Age              9091 non-null   int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          9091 non-null   float64\n",
      " 9   NumOfProducts    9091 non-null   int64  \n",
      " 10  HasCrCard        9091 non-null   int64  \n",
      " 11  IsActiveMember   9091 non-null   int64  \n",
      " 12  EstimatedSalary  9091 non-null   float64\n",
      " 13  Exited           9091 non-null   int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobacion de duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de duplicados = 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de duplicados =\", df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos los datos nulos y comprobamos que ya no tenemos ninguno.\n",
    "\n",
    "A demas verificamos si no tenemos valores duplicados, ya que podrian afectar a nuestro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminacion de columnas innecesarias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que tenemos columnas que no van a ayudar a nuestro modelo, las vamos a eliminar, estas son RowNumber, Surname y CustomerId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Surname'])\n",
    "df = df.drop(columns=['RowNumber'])\n",
    "df = df.drop(columns=['CustomerId'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorizacion de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que tenemos datos categoricos, tenemos que convertirlos a numericos para que nuestro modelo pueda trabajar con ellos. Especificamente Gender y Geography."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42     2.0       0.00              1          1   \n",
       "1          608   41     1.0   83807.86              1          0   \n",
       "2          502   42     8.0  159660.80              3          1   \n",
       "3          699   39     1.0       0.00              2          0   \n",
       "4          850   43     2.0  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1              True   \n",
       "1               1        112542.58       0             False   \n",
       "2               0        113931.57       1              True   \n",
       "3               0         93826.63       0              True   \n",
       "4               1         79084.10       0             False   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "0              False            False           True        False  \n",
       "1              False             True           True        False  \n",
       "2              False            False           True        False  \n",
       "3              False            False           True        False  \n",
       "4              False             True           True        False  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=['Geography', 'Gender'])\n",
    "\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division del conjunto de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este paso vamos a dividir nuestro conjunto de datos en 3 partes, train, validacion y test. Para poder entrenar nuestro modelo, validar que funciona correctamente y por ultimo testearlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_temp = train_test_split(df, test_size=0.2, random_state=12345)\n",
    "df_val, df_test = train_test_split(df_temp, test_size=0.25, random_state=12345)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escalado de Caracteristicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que algunas de nuestras columnas tienen valores muy altos y otras muy bajos, tenemos que escalarlas para que nuestro modelo pueda trabajar con ellas correctamente. Entre ellas tenemos CreditScore, Age, Tenure, Balance y EstimatedSalary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "num_columns = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "scaler.fit(df_train[num_columns])\n",
    "\n",
    "\n",
    "df_train[num_columns] = scaler.transform(df_train[num_columns])\n",
    "df_val[num_columns] = scaler.transform(df_val[num_columns])\n",
    "df_test[num_columns] = scaler.transform(df_test[num_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificacion del equilibrio de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exited\n",
      "0    0.795792\n",
      "1    0.204208\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_distribution = df_train['Exited'].value_counts(normalize=True)\n",
    "print(class_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que tenemos un desequilibrio de clases, ya que tenemos un 80% de clientes que no se han ido y un 20% que si se han ido. Esto puede afectar a nuestro modelo, ya que podria aprender a predecir que todos los clientes no se van a ir y tendriamos un modelo que no nos serviria para nada.\n",
    "\n",
    "Es por eso que tenemos que balancear las clases, para que nuestro modelo aprenda a predecir correctamente.\n",
    "\n",
    "En este caso vamos a utilizar la tecnica de upsampling, la cual consiste en duplicar los datos de la clase minoritaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('Exited', axis=1)\n",
    "y_train = df_train['Exited']\n",
    "\n",
    "minority_class = df_train[df_train['Exited'] == 1]\n",
    "\n",
    "# Duplicar por 3 la clase minoritaria para o\n",
    "oversampled_minority_class = pd.concat([minority_class] * 3, ignore_index=True)\n",
    "\n",
    "# Aleatorizar el orden de las filas (shuffle)\n",
    "oversampled_minority_class = shuffle(oversampled_minority_class, random_state=12345)\n",
    "\n",
    "# Combinar las filas duplicadas con las originales\n",
    "X_train_balanced = pd.concat([X_train, oversampled_minority_class.drop('Exited', axis=1)], ignore_index=True)\n",
    "y_train_balanced = pd.concat([y_train, oversampled_minority_class['Exited']], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora para corroborar vamos a ver el balance de clases de nuevo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exited\n",
      "1    0.506523\n",
      "0    0.493477\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_distribution_balanced = y_train_balanced.value_counts(normalize=True)\n",
    "print(class_distribution_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que ahora tenemos un 50% de clientes que se han ido y un 50% que no se han ido, lo cual es perfecto para nuestro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleccion de Modelos y Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccion Inicial de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta parte nos vamos a decidir por 3 modelos, los cuales son los siguientes:\n",
    "\n",
    "- LogisticRegression\n",
    "- DecisionTreeClassifier\n",
    "- RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "\n",
    "# Entrenar el modelo en el conjunto de entrenamiento\n",
    "logistic_regression_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predecir en el conjunto de validación\n",
    "y_valid_pred_logistic_regression = logistic_regression_model.predict(df_val.drop('Exited', axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7060117302052786\n",
      "Recall: 0.7299270072992701\n",
      "ROC AUC: 0.714963503649635\n",
      "F1 Score: 0.49937578027465673\n"
     ]
    }
   ],
   "source": [
    "# Calcular la precisión\n",
    "accuracy = accuracy_score(df_val['Exited'], y_valid_pred_logistic_regression)\n",
    "\n",
    "# Calcular el recall\n",
    "recall = recall_score(df_val['Exited'], y_valid_pred_logistic_regression)\n",
    "\n",
    "# Calcular el F1-score\n",
    "f1 = f1_score(df_val['Exited'], y_valid_pred_logistic_regression)\n",
    "\n",
    "# Calcular el ROC AUC\n",
    "roc_auc = roc_auc_score(df_val['Exited'], y_valid_pred_logistic_regression)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el modelo de regresion logistica nos da un F1 de 0.499, lo cual no es muy bueno, pero es un buen comienzo. Vamos a seguir probando con los otros modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar modelo\n",
    "decision_tree_model = DecisionTreeClassifier(random_state=12345)\n",
    "\n",
    "# Entrenar el modelo en el conjunto de entrenamiento\n",
    "decision_tree_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predecir en el conjunto de validación\n",
    "y_valid_pred_decision_tree = decision_tree_model.predict(df_val.drop('Exited', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7983870967741935\n",
      "Recall: 0.5182481751824818\n",
      "ROC AUC: 0.6935277573160115\n",
      "F1 Score: 0.5080500894454383\n"
     ]
    }
   ],
   "source": [
    "# Calcular la precisión\n",
    "accuracy = accuracy_score(df_val['Exited'], y_valid_pred_decision_tree)\n",
    "\n",
    "# Calcular el recall\n",
    "recall = recall_score(df_val['Exited'], y_valid_pred_decision_tree)\n",
    "\n",
    "# Calcular el F1-score\n",
    "f1 = f1_score(df_val['Exited'], y_valid_pred_decision_tree)\n",
    "\n",
    "# Calcular el ROC AUC\n",
    "roc_auc = roc_auc_score(df_val['Exited'], y_valid_pred_decision_tree)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el modelo de arbol de decision nos da un F1 de 0.508, lo cual es un poco mejor que el anterior, pero no es suficiente. Vamos a seguir probando con el ultimo modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar modelo\n",
    "random_forest_model = RandomForestClassifier(random_state=12345)\n",
    "\n",
    "# Entrenar el modelo en el conjunto de entrenamiento\n",
    "random_forest_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predecir en el conjunto de validación\n",
    "y_valid_pred_random_forest = random_forest_model.predict(df_val.drop('Exited', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8533724340175953\n",
      "Recall: 0.5401459854014599\n",
      "ROC AUC: 0.7361280385722896\n",
      "F1 Score: 0.5967741935483871\n"
     ]
    }
   ],
   "source": [
    "# Calcular la precisión\n",
    "accuracy = accuracy_score(df_val['Exited'], y_valid_pred_random_forest)\n",
    "\n",
    "# Calcular el recall\n",
    "recall = recall_score(df_val['Exited'], y_valid_pred_random_forest)\n",
    "\n",
    "# Calcular el F1-score\n",
    "f1 = f1_score(df_val['Exited'], y_valid_pred_random_forest)\n",
    "\n",
    "# Calcular el ROC AUC\n",
    "roc_auc = roc_auc_score(df_val['Exited'], y_valid_pred_random_forest)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver el modelo de random forest nos da un F1 de 0.596, lo cual es el mejor de los 3 modelos que hemos probado.\n",
    "\n",
    "Es por esto que vamos a indagar mas en este modelo para ver si podemos mejorarlo.\n",
    "\n",
    "Primero vamos a seleccionar los hiperparametros que mejor funcionan para este modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccion de Hiperparametros para Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: RandomForestClassifier(max_depth=9, n_estimators=81, random_state=12345)\n",
      "Best result: 0.6214177978883861\n",
      "Best n_estimators: 81\n",
      "Best max_depth: 9\n",
      "\n",
      "F1 score: 0.6214177978883861\n",
      "Accuracy score: 0.8159824046920822\n",
      "Recall score: 0.7518248175182481\n",
      "ROC AUC Score: 0.7919674546306837\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "\n",
    "for est in range(1, 100, 10):\n",
    "    for depth in range(1, 20, 2):\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        model.fit(X_train_balanced, y_train_balanced)\n",
    "        y_valid_pred_random_forest_hiper = model.predict(df_val.drop('Exited', axis=1))\n",
    "        result = f1_score(df_val['Exited'], y_valid_pred_random_forest_hiper)\n",
    "        if result > best_result:\n",
    "            best_model = model\n",
    "            best_result = result\n",
    "            best_est = est\n",
    "            best_depth = depth\n",
    "\n",
    "print(f\"Best model: {best_model}\")\n",
    "print(f\"Best result: {best_result}\")\n",
    "print(f\"Best n_estimators: {best_est}\")\n",
    "print(f\"Best max_depth: {best_depth}\")\n",
    "\n",
    "print()\n",
    "y_valid_pred_random_forest_hiper = best_model.predict(df_val.drop('Exited', axis=1))\n",
    "print(f\"F1 score: {f1_score(df_val['Exited'], y_valid_pred_random_forest_hiper)}\")\n",
    "print(f\"Accuracy score: {accuracy_score(df_val['Exited'], y_valid_pred_random_forest_hiper)}\")\n",
    "print(f\"Recall score: {recall_score(df_val['Exited'], y_valid_pred_random_forest_hiper)}\")\n",
    "print(f\"ROC AUC Score: {roc_auc_score(df_val['Exited'], y_valid_pred_random_forest_hiper)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que seleccionando los mejores hiperparametros para este modelo, podemos mejorar todos los valores de nuestro modelo, pero el que mas nos interesa es el F1, el cual pasa de 0.596 a 0.621, lo cual es una mejora bastante buena."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomando en cuenta todo lo anterior, podemos decir que el mejor modelo para este caso es el de Random Forest Classifier, ya que nos da un F1 de 0.621, el cual es el mejor de todos los modelos que hemos probado. \n",
    "\n",
    "Para este proyecto en el que buscamos predecir si un cliente tiene la posibilidad de irse del banco, es muy importante observar no solo el valor de F1, si no todos los demas aqui expuesto para poder tener un modelo lo mas eficiente posible.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
